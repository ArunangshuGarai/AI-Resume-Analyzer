"""
Script to verify all sample data has been generated correctly
"""

import os
from pathlib import Path
import pandas as pd
import yaml

def check_project_data():
    """Verify all required data files exist and are properly formatted"""
    
    print("ğŸ” Checking HR-Tech Challenge Data Generation")
    print("=" * 60)
    
    # Check directories
    data_dirs = [
        "data/resumes",
        "data/job_descriptions", 
        "data/employee_feedback"
    ]
    
    for dir_path in data_dirs:
        if Path(dir_path).exists():
            print(f"âœ… Directory exists: {dir_path}")
        else:
            print(f"âŒ Directory missing: {dir_path}")
    
    print("\nğŸ“„ Checking Resume Data:")
    print("-" * 30)
    
    # Check resumes
    resumes_dir = Path("data/resumes")
    if resumes_dir.exists():
        resume_files = list(resumes_dir.glob("*.txt"))
        print(f"âœ… Found {len(resume_files)} resume files")
        
        # Show sample resume files
        for i, resume_file in enumerate(resume_files[:5]):
            file_size = resume_file.stat().st_size
            print(f"   ğŸ“ {resume_file.name} ({file_size} bytes)")
        
        if len(resume_files) > 5:
            print(f"   ... and {len(resume_files) - 5} more resume files")
    else:
        print("âŒ No resumes directory found")
    
    print("\nğŸ“‹ Checking Job Description Data:")
    print("-" * 35)
    
    # Check job descriptions
    job_desc_dir = Path("data/job_descriptions")
    if job_desc_dir.exists():
        job_files = list(job_desc_dir.glob("*.yaml"))
        print(f"âœ… Found {len(job_files)} job description files")
        
        for job_file in job_files:
            print(f"   ğŸ“„ {job_file.name}")
            
            # Try to parse YAML
            try:
                with open(job_file, 'r') as f:
                    job_data = yaml.safe_load(f)
                    if 'required_skills' in job_data:
                        print(f"      âœ… Valid job description with skills")
                    else:
                        print(f"      âš ï¸ Missing required_skills section")
            except Exception as e:
                print(f"      âŒ YAML parsing error: {str(e)}")
    else:
        print("âŒ No job descriptions directory found")
    
    print("\nğŸ’¬ Checking Employee Feedback Data:")
    print("-" * 37)
    
    # Check employee feedback
    feedback_dir = Path("data/employee_feedback")
    if feedback_dir.exists():
        csv_files = list(feedback_dir.glob("*.csv"))
        yaml_files = list(feedback_dir.glob("*.yaml"))
        
        print(f"âœ… Found {len(csv_files)} CSV files and {len(yaml_files)} YAML files")
        
        for csv_file in csv_files:
            try:
                df = pd.read_csv(csv_file)
                print(f"   ğŸ“Š {csv_file.name}: {len(df)} rows, {len(df.columns)} columns")
                
                # Check required columns
                required_columns = ['employee_id', 'feedback_text', 'sentiment', 'rating']
                missing_cols = [col for col in required_columns if col not in df.columns]
                
                if missing_cols:
                    print(f"      âš ï¸ Missing columns: {missing_cols}")
                else:
                    print(f"      âœ… All required columns present")
                
                # Show sentiment distribution
                if 'sentiment' in df.columns:
                    sentiment_counts = df['sentiment'].value_counts()
                    print(f"      ğŸ“ˆ Sentiment distribution: {dict(sentiment_counts)}")
                
            except Exception as e:
                print(f"      âŒ CSV reading error: {str(e)}")
        
        for yaml_file in yaml_files:
            print(f"   ğŸ“„ {yaml_file.name}")
    else:
        print("âŒ No employee feedback directory found")
    
    print("\nğŸ¯ Data Quality Summary:")
    print("-" * 25)
    
    # Summary statistics
    total_files = 0
    
    if resumes_dir.exists():
        resume_count = len(list(resumes_dir.glob("*.txt")))
        total_files += resume_count
        print(f"ğŸ“ Resume files: {resume_count}")
    
    if job_desc_dir.exists():
        job_count = len(list(job_desc_dir.glob("*.yaml")))
        total_files += job_count
        print(f"ğŸ“‹ Job description files: {job_count}")
    
    if feedback_dir.exists():
        feedback_count = len(list(feedback_dir.glob("*.csv")))
        total_files += feedback_count
        print(f"ğŸ’¬ Feedback data files: {feedback_count}")
    
    print(f"ğŸ“Š Total data files: {total_files}")
    
    # Check if we have minimum required data
    min_requirements = {
        "resumes": 10,
        "job_descriptions": 1,
        "feedback_entries": 100
    }
    
    print(f"\nâœ… Minimum Requirements Check:")
    print(f"-" * 32)
    
    # Check resumes
    if resumes_dir.exists():
        resume_count = len(list(resumes_dir.glob("*.txt")))
        status = "âœ…" if resume_count >= min_requirements["resumes"] else "âš ï¸"
        print(f"{status} Resumes: {resume_count}/{min_requirements['resumes']} minimum")
    
    # Check job descriptions
    if job_desc_dir.exists():
        job_count = len(list(job_desc_dir.glob("*.yaml")))
        status = "âœ…" if job_count >= min_requirements["job_descriptions"] else "âš ï¸"
        print(f"{status} Job descriptions: {job_count}/{min_requirements['job_descriptions']} minimum")
    
    # Check feedback entries
    if feedback_dir.exists() and (feedback_dir / "employee_feedback.csv").exists():
        try:
            df = pd.read_csv(feedback_dir / "employee_feedback.csv")
            feedback_count = len(df)
            status = "âœ…" if feedback_count >= min_requirements["feedback_entries"] else "âš ï¸"
            print(f"{status} Feedback entries: {feedback_count}/{min_requirements['feedback_entries']} minimum")
        except:
            print(f"âš ï¸ Could not read feedback data")
    
    print(f"\nğŸ‰ Phase 2 Data Generation Status:")
    print(f"{'=' * 35}")
    
    # Overall status
    all_good = True
    
    if not resumes_dir.exists() or len(list(resumes_dir.glob("*.txt"))) < 10:
        all_good = False
        print("âš ï¸ Need more resume files")
    
    if not job_desc_dir.exists() or len(list(job_desc_dir.glob("*.yaml"))) < 1:
        all_good = False
        print("âš ï¸ Need job description file")
    
    if not feedback_dir.exists() or not (feedback_dir / "employee_feedback.csv").exists():
        all_good = False
        print("âš ï¸ Need employee feedback data")
    
    if all_good:
        print("ğŸ‰ ALL DATA READY! Phase 2 complete - Ready for Phase 3!")
        print("Next: Start building the AI models and prompt engineering")
    else:
        print("ğŸ“‹ Please complete the missing data generation steps above")
    
    return all_good

def show_sample_data():
    """Show samples of generated data"""
    print(f"\nğŸ“– Sample Data Preview:")
    print(f"=" * 25)
    
    # Show sample resume
    resumes_dir = Path("data/resumes")
    if resumes_dir.exists():
        resume_files = list(resumes_dir.glob("*.txt"))
        if resume_files:
            print(f"\nğŸ“ Sample Resume ({resume_files[0].name}):")
            print("-" * 40)
            with open(resume_files[0], 'r') as f:
                content = f.read()
                # Show first 300 characters
                print(content[:300] + "..." if len(content) > 300 else content)
    
    # Show sample feedback
    feedback_file = Path("data/employee_feedback/employee_feedback.csv")
    if feedback_file.exists():
        print(f"\nğŸ’¬ Sample Employee Feedback:")
        print("-" * 32)
        try:
            df = pd.read_csv(feedback_file)
            # Show first few rows with key columns
            key_cols = ['employee_id', 'sentiment', 'rating', 'feedback_text']
            available_cols = [col for col in key_cols if col in df.columns]
            
            if available_cols:
                sample_df = df[available_cols].head(3)
                for _, row in sample_df.iterrows():
                    print(f"ID: {row.get('employee_id', 'N/A')}")
                    print(f"Sentiment: {row.get('sentiment', 'N/A')} | Rating: {row.get('rating', 'N/A')}")
                    feedback_text = row.get('feedback_text', 'N/A')
                    print(f"Feedback: {feedback_text[:100]}{'...' if len(feedback_text) > 100 else ''}")
                    print("-" * 40)
        except Exception as e:
            print(f"Error reading feedback data: {str(e)}")

if __name__ == "__main__":
    data_ready = check_project_data()
    
    if data_ready:
        show_sample_data()
        
        print(f"\nğŸš€ Ready for Phase 3: AI Model Development!")
        print("Run: python -c \"print('Phase 2 Complete - Data Ready!')\"")
    else:
        print(f"\nğŸ“‹ Complete remaining data generation tasks first")
        print("Then re-run: python verify_data.py")